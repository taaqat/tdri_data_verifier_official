import pandas as pd 
import numpy as np
import json
import argparse
from constants import RULES, Config, classification_columns, Rank_col_schema, Extend_class_schema
import streamlit as st
import time


def stream_write(text, time_interval = 0.04):

    def gen_stream(text):
        for word in text:
            yield word
            time.sleep(time_interval)

    st.write_stream(gen_stream(text))

class Verify():

    def __init__(self, classification_data):
        self.classification = classification_data
        self.chart_brand_details = {"subcategory": {},
                                    "further_subcategory": {}}
        self.chart_brand_extend_details = {}
        self.chart_brand_extend_cross_details = {}
        self.chart_brand_extend_image_details = {}
        self.chart_brand_comment_counts_details = {}
        self.chart_others_details = {}
        self.chart_trends_details = {}

    def column_assertion(self, data, chart_name):
        stream_write("ğŸ”† æª¢æŸ¥æ˜¯å¦ç¼ºå°‘ç‰¹å®šæ¬„ä½...")
        if_any = False
        for col in Config[chart_name]:
            if col not in data.columns:
                if_any = True
                stream_write(f"âš ï¸ missing column: {col}")

        if not if_any:
            stream_write("âœ… æ²’æœ‰ç¼ºå¤±é‡è¦æ¬„ä½")

    def null_analysis(self, data, chart_name):
        st.divider()
        stream_write(f"\nğŸ“Š ç¸½åˆ—æ•¸ï¼š{len(data)}")
        table = (pd.DataFrame(data[Config[chart_name]].isna().sum())
         .rename(columns = {0: "count"}))
        table['proportion'] = table['count'] / len(data)
        table = table.astype("object")
        table['count'] = table['count'].apply(lambda x: f"{int(x)}")
        table['proportion'] = table['proportion'].apply(lambda x: f"{x * 100:.2f} %")

        stream_write("ğŸ”† å„æ¬„ä½ç©ºå€¼åˆ†ä½ˆ")
        st.dataframe(table.T)

    def duplicates_analysis(self, data, chart_name):
        st.divider()
        assert chart_name in ["products", "products_extend"], "duplicates analysis is only available for 'products' and 'products_extend' tables"

        stream_write("\nğŸ”† æ­£åœ¨æª¢æŸ¥é‡è¤‡åˆ—...")
        if chart_name == "products":
            data["dup"] = data.duplicated(subset = ["source_product_id"])
            dup_ids = data[data["dup"]]["id"].tolist()
            if dup_ids != []:
                stream_write("ğŸ”” Products æœ‰é‡è¤‡å€¼ã€‚")
                return dup_ids
            else:
                stream_write("âœ… æ²’æœ‰é‡è¤‡çš„ç”¢å“è³‡æ–™")
        
        if chart_name == "products_extend":
            data["dup"] = data.duplicated(subset = ["source_product_id", "extend_class", "extend_subclass", "extend_detail"])
            dup_ids = data[data["dup"]]["id"].tolist()
            if dup_ids != []:
                stream_write("ğŸ”” Products Extend æœ‰é‡è¤‡å€¼ã€‚")
                return dup_ids
            else:
                stream_write("âœ… æ²’æœ‰é‡è¤‡çš„ç”¢å“æ“´å¢å±¬æ€§è³‡æ–™")
        
        

            


    def classification_check(self, data, statstype = "further_subcategory"):
        st.divider()
        stream_write("\nğŸ”† æ­£åœ¨æª¢æŸ¥åˆ†é¡çµ„åˆ...")
        assert statstype in ["subcategory", "further_subcategory", "mixed"] 
        incorrect_classified_ids = []

        if statstype == "mixed":
            """
            ç•¶è¡¨ä¸­åŒæ™‚æœ‰å­é¡èˆ‡å“é¡å±¤ç´šçš„è³‡æ–™ -> åˆ†é–‹è™•ç†
            """
            # * å­é¡
            class_cols = ["category", "subcategory", "further_subcategory"]
            further_sub_data = data[data['stats_type'] == "further_subcategory"]
            for _, row in further_sub_data.dropna(subset = class_cols).iterrows():
                class_ = "_".join([row[col] for col in class_cols]) 
                if class_ not in self.classification['classification_further_subcategory'].tolist():
                    incorrect_classified_ids.append(row['id'])

            # * å“é¡
            class_cols = ["category", "subcategory"]
            sub_data = data[data['stats_type'] == "subcategory"]
            for _, row in sub_data.dropna(subset = class_cols).iterrows():
                class_ = "_".join([row[col] for col in class_cols]) 
                if class_ not in self.classification['classification_subcategory'].tolist():
                    incorrect_classified_ids.append(row['id'])

        else:
            """
            ç•¶è¡¨ä¸­åªæœ‰å­é¡æˆ–å“é¡å…¶ä¸€å±¤ç´šçš„è³‡æ–™
            """
            if statstype == "further_subcategory":
                class_cols = classification_columns
            elif statstype == "subcategory":
                class_cols = ["category", "subcategory"]
            for _, row in data.dropna(subset = class_cols).iterrows():
                class_ = "_".join([row[col] for col in class_cols]) 
                if class_ not in self.classification['classification_' + statstype].tolist():
                    incorrect_classified_ids.append(row['id'])

        stream_write(f"ğŸ”” å…±æœ‰ {len(incorrect_classified_ids)} æ¯”è³‡æ–™çš„åˆ†é¡çµ„åˆä¸å­˜åœ¨æ–¼åˆ†é¡è³‡æ–™è¡¨ä¸­ï¼Œä½”ç¸½è³‡æ–™çš„ {len(incorrect_classified_ids) / len(data) * 100 :.2f}%")
        return incorrect_classified_ids
    
    def rank_verifier(self, data, chart_name):
        st.divider()
        schema = Rank_col_schema[chart_name]

        

        if "brand" in schema.keys():
            stream_write("\nğŸ”† é©—è­‰å“ç‰Œæ’åæ¬„ä½...")
            col_name = schema["brand"][0]
            range_   = schema["brand"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å“ç‰Œæ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

        if "factor_stats" in schema.keys():
            stream_write("\nğŸ”† é©—è­‰å› ç´ çµ±è¨ˆæ’åæ¬„ä½...")
            col_name  = schema["factor_stats"][0]
            range_    = schema["factor_stats"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å› ç´ çµ±è¨ˆæ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

        if "factor_alphabet" in schema.keys():
            stream_write("\nğŸ”† é©—è­‰å› ç´ åç¨±æ’åæ¬„ä½...")
            col_name  = schema["factor_alphabet"][0]
            range_    = schema["factor_alphabet"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å› ç´ åç¨±æ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

        if "element_stats" in schema.keys():
            stream_write("\nğŸ”† (chart_trends) é©—è­‰å› ç´ æ•¸é‡æ’åæ¬„ä½...")
            col_name  = schema["element_stats"][0]
            range_    = schema["element_stats"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å› ç´ æ•¸é‡æ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)
        
        if "element_alphabet" in schema.keys():
            stream_write("\nğŸ”† (chart_trends) é©—è­‰å› ç´ åç¨±æ’åæ¬„ä½...")
            col_name  = schema["element_alphabet"][0]
            range_    = schema["element_alphabet"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å› ç´ åç¨±æ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

        if "labels_rank" in schema.keys():
            stream_write("\nğŸ”† (chart_trends) é©—è­‰æ¨™ç±¤æ•¸é‡æ’åæ¬„ä½...")
            col_name  = schema["labels_rank"][0]
            range_    = schema["labels_rank"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” æ¨™ç±¤æ•¸é‡æ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

    def check_extend_class(self, data, chart_name):
        st.divider()
        stream_write("\nğŸ”† æª¢æŸ¥æ˜¯å¦ç¼ºå°‘æ“´å……å±¬æ€§...")
        extend_classes_status = pd.DataFrame(columns = Extend_class_schema[chart_name])
        for col in extend_classes_status.columns:
            if col not in data['extend_class'].unique():
                extend_classes_status.loc["æ˜¯å¦å‡ºç¾åœ¨è³‡æ–™è¡¨ä¸­", col] = "âŒ"
            else:
                extend_classes_status.loc["æ˜¯å¦å‡ºç¾åœ¨è³‡æ–™è¡¨ä¸­", col] = "âœ…"
        st.dataframe(extend_classes_status)


        
        if chart_name == "chart_brand_comment_counts":
            return 
        stream_write("\nğŸ”† å­æ“´å……å±¬æ€§ç©ºå€¼åˆ†æ")
        subclass_decomp = (data
            .groupby(["extend_class"])
            .apply(lambda group: 
                    pd.DataFrame(
                            {
                                "extend_subclassç‚ºç©ºä¹‹åˆ—æ•¸": pd.Series(group["extend_subclass"].isna().sum()),
                                "extend_subclassç‚ºç©ºæ¯”ä¾‹":  pd.Series(group["extend_subclass"].isna().sum() / len(group)),
                                "extend_unitç‚ºç©ºä¹‹åˆ—æ•¸": pd.Series(group["extend_unit"].isna().sum()),
                                "extend_unitç‚ºç©ºæ¯”ä¾‹":  pd.Series(group["extend_unit"].isna().sum() / len(group))
                            }   
                                if chart_name == "products_extend" else
                            {
                                "extend_subclassç‚ºç©ºä¹‹åˆ—æ•¸": pd.Series(group["extend_subclass"].isna().sum()),
                                "extend_subclassç‚ºç©ºæ¯”ä¾‹":  pd.Series(group["extend_subclass"].isna().sum() / len(group))
                            }
                         )
                    , include_groups =  False))
        subclass_decomp["extend_subclassç‚ºç©ºæ¯”ä¾‹"] = subclass_decomp["extend_subclassç‚ºç©ºæ¯”ä¾‹"].apply(lambda x: f"{x * 100:.2f}%")
        if chart_name == "products_extend":
            subclass_decomp["extend_unitç‚ºç©ºæ¯”ä¾‹"] = subclass_decomp["extend_unitç‚ºç©ºæ¯”ä¾‹"].apply(lambda x: f"{x * 100:.2f}%")

        st.dataframe(subclass_decomp)
        st.caption("""è¨ˆç®—æ–¹å¼ï¼š
                   
1. groupby("extend_class")ï¼Œè¨ˆç®— extend_subclass (extend_unit) çš„ç©ºå€¼æ•¸

2. å°‡ä¸Šæ­¥é©Ÿç®—å‡ºçš„æ•¸é‡ï¼Œé™¤ä»¥æ¯å€‹ group (extend_class) çš„åˆ—æ•¸ï¼Œè¨ˆç®—æ¯”ä¾‹""")

    def verify_decimal(self, data):
        st.divider()
        stream_write("\nğŸ”† æª¢æŸ¥å°æ•¸é»è¦ç¯„...")

        df = data.copy()

        if "extend_stats" in df.columns:
            
            # è®€å– json å­—ä¸²
            df['extend_stats'] = df['extend_stats'].apply(json.loads)

            # json æ¨™æº–åŒ–
            df = pd.concat([ 
                    df,
                    pd.json_normalize(df["extend_stats"])
                ], axis = 1
            )


            # * Check ratio
            if "ratio" in df.columns:
                df["ratio"] = df["ratio"].astype(str)
                df["ratio_decimal_test"] = df["ratio"].apply(lambda x: len(x.split(".")[1]) > 3 if len(x.split(".")) > 1 else False)
                df["ratio_ends_with_zero"] = df["ratio"].apply(lambda x: int(x.split(".")[1]) == 0 if len(x.split(".")) > 1 else False)
                sum_violating_1 = sum(df['ratio_decimal_test'])
                sum_violating_2 = sum(df['ratio_ends_with_zero'])
                if sum_violating_1 > 0:
                    stream_write(f"ğŸ”” extend_stats -> ratio: {sum_violating_1} åˆ—è¶…é 3 ä½å°æ•¸" )
                if sum_violating_2 > 0:
                    stream_write(f"ğŸ”” extend_stats -> ratio: {sum_violating_2} åˆ—å°æ•¸ä»¥ 0 çµå°¾" )

            # * Check avg_price
            if "avg_price" in df.columns:
                df["avg_price"] = df["avg_price"].astype(str)
                df["avg_price_decimal_test"] = df["avg_price"].apply(lambda x: len(x.split(".")[1]) > 3 if len(x.split(".")) > 1 else False)
                df["avg_price_ends_with_zero"] = df["avg_price"].apply(lambda x: int(x.split(".")[1]) == 0 if len(x.split(".")) > 1 else False)
                sum_violating_1 = sum(df['avg_price_decimal_test'])
                sum_violating_2 = sum(df['avg_price_ends_with_zero'])
                if sum_violating_1 > 0:
                    stream_write(f"ğŸ”” extend_stats -> avg_price: {sum_violating_1} åˆ—è¶…é 3 ä½å°æ•¸" )
                if sum_violating_2 > 0:
                    stream_write(f"ğŸ”” extend_stats -> avg_price: {sum_violating_2} åˆ—å°æ•¸ä»¥ 0 çµå°¾" )

            del df
            stream_write("âœ… æª¢æŸ¥å®Œæˆ")
        else:
            stream_write("âœ… æ²’æœ‰ extend_stats æ¬„ä½")

    # ==========================================================================================================================
    # * * * ä»¥ä¸‹ç‚ºå„è¡¨çš„è³‡æ–™é©—è­‰å‡½æ•¸ã€‚æœƒç”¨åˆ°ä¸Šé¢çš„è¼”åŠ©å‡½æ•¸ * * * 
    # ==========================================================================================================================

    def check_products(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "products")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "products")

        # é‡è¤‡å€¼æª¢æ¸¬
        dup_ids = self.duplicates_analysis(data, "products")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        incorrect_classified_ids = self.classification_check(data)

        return dup_ids
        

    def check_products_extend(self, data):


        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "products_extend")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "products_extend")

        # é‡è¤‡å€¼æª¢æ¸¬
        dup_ids = self.duplicates_analysis(data, "products_extend")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data)

        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "products_extend")

        return dup_ids

    def check_chart_brand(self, data, statstype):


        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brand_" + statstype)
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brand_" + statstype)
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, statstype)

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brand")

    def check_chart_brand_extend(self, data):


        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brand_extend")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brand_extend")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brand_extend")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brand_extend")

        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)

    def check_chart_brand_extend_cross(self, data):


        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brand_extend_cross")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brand_extend_cross")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brand_extend_cross")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brand_extend_cross")

        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)

    def check_chart_brand_extend_image(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brand_extend_image")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brand_extend_image")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.chart_brand_extend_image_details["incorrect_classified_ids"] = self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brand_extend_image")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brand_extend_image")

        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)

    def check_chart_brand_comment_counts(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brand_comment_counts")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brand_comment_counts")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brand_comment_counts")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brand_comment_counts")

        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)
    
    def check_chart_others(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_others")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_others")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_others")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_others")

        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)

    def check_chart_trends(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_trends")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_trends")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_trends")

        

        

    



        

        

if __name__ == "__main__":

    args = parse_args()

    classification = pd.read_excel(args.classification)[["domain", "category", "subcategory", "further_subcategory"]]
    classification['classification_further_subcategory'] = classification.apply(lambda row: "_".join([row[col] for col in classification_columns]), axis = 1)
    classification['classification_subcategory'] = classification.apply(lambda row: "_".join([row[col] for col in classification_columns if col != "further_subcategory"]), axis = 1)
    data_verifier = Verify(classification)

    print(RULES)

    if args.products:
        data_verifier.check_products(args.products)

    if args.products_extend:
        data_verifier.check_products_extend(args.products_extend)

    if args.chart_brand_subcategory:
        data_verifier.check_chart_brand(args.chart_brand_subcategory, "subcategory")

    if args.chart_brand_further_subcategory:
        data_verifier.check_chart_brand(args.chart_brand_further_subcategory, "subcategory")

    if args.chart_brand_extend:
        data_verifier.check_chart_brand_extend(args.chart_brand_extend)

    if args.chart_brand_extend_cross:
        data_verifier.check_chart_brand_extend_cross(args.chart_brand_extend_cross)

    if args.chart_brand_extend_image:
        data_verifier.check_chart_brand_extend_image(args.chart_brand_extend_image)

    if args.chart_brand_comment_counts:
        data_verifier.check_chart_brand_comment_counts(args.chart_brand_comment_counts)

    if args.chart_others:
        data_verifier.check_chart_others(args.chart_others)

    if args.chart_trends:
        data_verifier.check_chart_trends(args.chart_trends)




