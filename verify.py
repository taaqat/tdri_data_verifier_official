import pandas as pd
import numpy as np
import json
import argparse
import streamlit as st
import time
import os
import sys
from constants import RULES, Config, classification_columns, Rank_col_schema, Extend_class_schema, CATEGORY_COVERAGE_THRESHOLD


def is_testing_environment():
    """åˆ¤æ–·æ˜¯å¦åœ¨æ¸¬è©¦ç’°å¢ƒä¸­é‹è¡Œ"""
    return 'PYTEST_CURRENT_TEST' in os.environ or any('test' in arg.lower() for arg in sys.argv)

def safe_st_call(func, *args, **kwargs):
    """å®‰å…¨åœ°èª¿ç”¨ Streamlit å‡½æ•¸ï¼Œåœ¨æ¸¬è©¦ç’°å¢ƒä¸­ä¸æœƒæ‹‹å‡ºç•°å¸¸"""
    if is_testing_environment():
        return None
    try:
        return func(*args, **kwargs)
    except Exception:
        # åœ¨é Streamlit ç’°å¢ƒä¸­é‹è¡Œæ™‚å¿½ç•¥éŒ¯èª¤
        return None

def stream_write(text, time_interval = 0.04):
    """å¸¶æœ‰æµå¼æ•ˆæœçš„æ–‡å­—è¼¸å‡ºï¼Œåœ¨æ¸¬è©¦ç’°å¢ƒä¸­ä¸æœƒä½¿ç”¨å»¶é²æ•ˆæœ"""
    is_test = is_testing_environment()
    
    def gen_stream(text):
        for word in text:
            yield word
            # åœ¨æ¸¬è©¦æ™‚ä¸è¦å»¶é²
            if not is_test:
                time.sleep(time_interval)
    
    try:
        # åœ¨æ¸¬è©¦ç’°å¢ƒä¸­ï¼Œåªè¼¸å‡ºåˆ°æ§åˆ¶å°
        if is_test:
            print(text)
        else:
            st.write_stream(gen_stream(text))
    except Exception:
        # åœ¨ streamlit ä¸Šä¸‹æ–‡å¤–ï¼Œå›é€€åˆ°æ¨™æº–è¼¸å‡º
        print(text)

class Verify():
    def __init__(self, classification_data, file_name=None):
        self.classification = classification_data
        self.file_name = file_name  # æ–°å¢æª”æ¡ˆåç¨±åƒæ•¸ï¼Œå…è¨±ç‚º None
        self.chart_brand_details = {"subcategory": {},
                                    "further_subcategory": {}}
        self.chart_brand_extend_details = {}
        self.chart_brand_extend_cross_details = {}
        self.chart_brand_extend_image_details = {}
        self.chart_brand_comment_counts_details = {}
        self.chart_others_details = {}
        self.chart_trends_details = {}
        self.category_coverage_details = {}
        self.empty_cells_details = {}
        self.duplicated_products_details = {}
        
    def check_chart_brands_extend(self, data):
        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brands_extend")
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brands_extend")
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")
        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brands_extend")
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brands_extend")
        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)

    def column_assertion(self, data, chart_name):
        stream_write("ğŸ”† æª¢æŸ¥æ˜¯å¦ç¼ºå°‘ç‰¹å®šæ¬„ä½...")
        if_any = False
        for col in Config[chart_name]:
            if col not in data.columns:
                if_any = True
                stream_write(f"âš ï¸ missing column: {col}")

        if not if_any:
            stream_write("âœ… æ²’æœ‰ç¼ºå¤±é‡è¦æ¬„ä½")

    def null_analysis(self, data, chart_name):
        st.divider()
        stream_write(f"\nğŸ“Š ç¸½åˆ—æ•¸ï¼š{len(data)}")
        table = (pd.DataFrame(data[Config[chart_name]].isna().sum())
         .rename(columns = {0: "count"}))
        table['proportion'] = table['count'] / len(data)
        table = table.astype("object")
        table['count'] = table['count'].apply(lambda x: f"{int(x)}")
        table['proportion'] = table['proportion'].apply(lambda x: f"{x * 100:.2f} %")

        stream_write("ğŸ”† å„æ¬„ä½ç©ºå€¼åˆ†ä½ˆ")
        st.dataframe(table.T)

    def duplicates_analysis(self, data, chart_name):
        st.divider()
        assert chart_name in ["products", "products_extend"], "duplicates analysis is only available for 'products' and 'products_extend' tables"

        stream_write("\nğŸ”† æª¢æŸ¥é‡è¤‡åˆ—...")
        if chart_name == "products":
            data["dup"] = data.duplicated(subset = ["source_product_id"])
            dup_ids = data[data["dup"]]["id"].tolist()
            if dup_ids != []:
                stream_write("ğŸ”” Products æœ‰é‡è¤‡å€¼ã€‚")
                return dup_ids
            else:
                stream_write("âœ… æ²’æœ‰é‡è¤‡çš„ç”¢å“è³‡æ–™")
        
        if chart_name == "products_extend":
            data["dup"] = data.duplicated(subset = ["source_product_id", "extend_class", "extend_subclass", "extend_detail"])
            dup_ids = data[data["dup"]]["id"].tolist()
            if dup_ids != []:
                stream_write("ğŸ”” Products Extend æœ‰é‡è¤‡å€¼ã€‚")
                return dup_ids
            else:
                stream_write("âœ… æ²’æœ‰é‡è¤‡çš„ç”¢å“æ“´å¢å±¬æ€§è³‡æ–™")
        
        

            


    def classification_check(self, data, statstype = "further_subcategory"):
        st.divider()
        stream_write("\nğŸ”† æª¢æŸ¥åˆ†é¡çµ„åˆ...")
        assert statstype in ["subcategory", "further_subcategory", "mixed"] 
        incorrect_classified_ids = []

        if statstype == "mixed":
            """
            ç•¶è¡¨ä¸­åŒæ™‚æœ‰å­é¡èˆ‡å“é¡å±¤ç´šçš„è³‡æ–™ -> åˆ†é–‹è™•ç†
            """
            # * å­é¡
            class_cols = ["category", "subcategory", "further_subcategory"]
            further_sub_data = data[data['stats_type'] == "further_subcategory"]
            for _, row in further_sub_data.dropna(subset = class_cols).iterrows():
                class_ = "_".join([row[col] for col in class_cols]) 
                if class_ not in self.classification['classification_further_subcategory'].tolist():
                    incorrect_classified_ids.append(row['id'])

            # * å“é¡
            class_cols = ["category", "subcategory"]
            sub_data = data[data['stats_type'] == "subcategory"]
            for _, row in sub_data.dropna(subset = class_cols).iterrows():
                class_ = "_".join([row[col] for col in class_cols]) 
                if class_ not in self.classification['classification_subcategory'].tolist():
                    incorrect_classified_ids.append(row['id'])

            count = len(incorrect_classified_ids)

        else:
            """
            ç•¶è¡¨ä¸­åªæœ‰å­é¡æˆ–å“é¡å…¶ä¸€å±¤ç´šçš„è³‡æ–™
            """
            if statstype == "further_subcategory":
                class_cols = classification_columns
            elif statstype == "subcategory":
                class_cols = ["category", "subcategory"]
            count = 0
            for _, row in data.dropna(subset = class_cols).iterrows():
                class_ = "_".join([row[col] for col in class_cols]) 
                if class_ not in self.classification['classification_' + statstype].tolist():
                    count += 1
                    try:
                        incorrect_classified_ids.append(row['id'])
                    except:
                        try:
                            # * æ–°å¢ reference å ±è¡¨çš„ä¾‹å¤–è™•ç†
                            incorrect_classified_ids.append(row['reference_id'])
                        except:
                            pass

        stream_write(f"ğŸ”” å…±æœ‰ {count} ç­†è³‡æ–™çš„åˆ†é¡çµ„åˆä¸å­˜åœ¨æ–¼åˆ†é¡è³‡æ–™è¡¨ä¸­ï¼Œä½”ç¸½è³‡æ–™çš„ {count / len(data) * 100 :.2f}%")
        return incorrect_classified_ids
    
    def rank_verifier(self, data, chart_name):
        st.divider()
        schema = Rank_col_schema[chart_name]

        

        if "brand" in schema.keys():
            stream_write("\nğŸ”† é©—è­‰å“ç‰Œæ’åæ¬„ä½...")
            col_name = schema["brand"][0]
            range_   = schema["brand"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å“ç‰Œæ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

        if "factor_stats" in schema.keys():
            stream_write("\nğŸ”† é©—è­‰å› ç´ çµ±è¨ˆæ’åæ¬„ä½...")
            col_name  = schema["factor_stats"][0]
            range_    = schema["factor_stats"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å› ç´ çµ±è¨ˆæ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

        if "factor_alphabet" in schema.keys():
            stream_write("\nğŸ”† é©—è­‰å› ç´ åç¨±æ’åæ¬„ä½...")
            col_name  = schema["factor_alphabet"][0]
            range_    = schema["factor_alphabet"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å› ç´ åç¨±æ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

        if "element_stats" in schema.keys():
            stream_write("\nğŸ”† (chart_trends) é©—è­‰å› ç´ æ•¸é‡æ’åæ¬„ä½...")
            col_name  = schema["element_stats"][0]
            range_    = schema["element_stats"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å› ç´ æ•¸é‡æ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)
        
        if "element_alphabet" in schema.keys():
            stream_write("\nğŸ”† (chart_trends) é©—è­‰å› ç´ åç¨±æ’åæ¬„ä½...")
            col_name  = schema["element_alphabet"][0]
            range_    = schema["element_alphabet"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” å› ç´ åç¨±æ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

        if "labels_rank" in schema.keys():
            stream_write("\nğŸ”† (chart_trends) é©—è­‰æ¨™ç±¤æ•¸é‡æ’åæ¬„ä½...")
            col_name  = schema["labels_rank"][0]
            range_    = schema["labels_rank"][1]
            formatted_values = data[col_name].apply(
                lambda x: str(int(x)) if pd.notna(x) and isinstance(x, (int, float)) and x == int(x) 
                else str(x)
            ).unique().tolist()
            stream_write(f"ğŸ”” æ¨™ç±¤æ•¸é‡æ’å")
            stream_write(f"- è³‡æ–™ä¸­çš„åæ¬¡ï¼š{sorted(formatted_values)}", 0.002)
            stream_write(f"- è¦ç¯„åæ¬¡ï¼š {set([i + 1 for i in range(range_)] + [999])}", 0.002)

    def check_extend_class(self, data, chart_name):
        st.divider()
        stream_write("\nğŸ”† æª¢æŸ¥æ˜¯å¦ç¼ºå°‘æ“´å……å±¬æ€§...")
        extend_classes_status = pd.DataFrame(columns = Extend_class_schema[chart_name])
        for col in extend_classes_status.columns:
            if col not in data['extend_class'].unique():
                extend_classes_status.loc["æ˜¯å¦å‡ºç¾åœ¨è³‡æ–™è¡¨ä¸­", col] = "âŒ"
            else:
                extend_classes_status.loc["æ˜¯å¦å‡ºç¾åœ¨è³‡æ–™è¡¨ä¸­", col] = "âœ…"
        st.dataframe(extend_classes_status)


        
        if chart_name == "chart_brand_comment_counts":
            return 
        stream_write("\nğŸ”† å­æ“´å……å±¬æ€§ç©ºå€¼åˆ†æ")
        subclass_decomp = (data
            .groupby(["extend_class"])
            .apply(lambda group: 
                    pd.DataFrame(
                            {
                                "extend_subclassç‚ºç©ºä¹‹åˆ—æ•¸": pd.Series(group["extend_subclass"].isna().sum()),
                                "extend_subclassç‚ºç©ºæ¯”ä¾‹":  pd.Series(group["extend_subclass"].isna().sum() / len(group)),
                                "extend_unitç‚ºç©ºä¹‹åˆ—æ•¸": pd.Series(group["extend_unit"].isna().sum()),
                                "extend_unitç‚ºç©ºæ¯”ä¾‹":  pd.Series(group["extend_unit"].isna().sum() / len(group))
                            }   
                                if chart_name == "products_extend" else
                            {
                                "extend_subclassç‚ºç©ºä¹‹åˆ—æ•¸": pd.Series(group["extend_subclass"].isna().sum()),
                                "extend_subclassç‚ºç©ºæ¯”ä¾‹":  pd.Series(group["extend_subclass"].isna().sum() / len(group))
                            }
                         )
                    , include_groups =  False))
        subclass_decomp["extend_subclassç‚ºç©ºæ¯”ä¾‹"] = subclass_decomp["extend_subclassç‚ºç©ºæ¯”ä¾‹"].apply(lambda x: f"{x * 100:.2f}%")
        if chart_name == "products_extend":
            subclass_decomp["extend_unitç‚ºç©ºæ¯”ä¾‹"] = subclass_decomp["extend_unitç‚ºç©ºæ¯”ä¾‹"].apply(lambda x: f"{x * 100:.2f}%")

        st.dataframe(subclass_decomp)
        st.caption("""è¨ˆç®—æ–¹å¼ï¼š
                   
1. groupby("extend_class")ï¼Œè¨ˆç®— extend_subclass (extend_unit) çš„ç©ºå€¼æ•¸

2. å°‡ä¸Šæ­¥é©Ÿç®—å‡ºçš„æ•¸é‡ï¼Œé™¤ä»¥æ¯å€‹ group (extend_class) çš„åˆ—æ•¸ï¼Œè¨ˆç®—æ¯”ä¾‹""")

    def verify_decimal(self, data):
        st.divider()
        stream_write("\nğŸ”† æª¢æŸ¥å°æ•¸é»è¦ç¯„...")

        df = data.copy()

        if "extend_stats" in df.columns:
            
            # è®€å– json å­—ä¸²
            df['extend_stats'] = df['extend_stats'].apply(json.loads)

            # json æ¨™æº–åŒ–
            df = pd.concat([ 
                    df,
                    pd.json_normalize(df["extend_stats"])
                ], axis = 1
            )


            # * Check ratio
            if "ratio" in df.columns:
                df["ratio"] = df["ratio"].astype(str)
                df["ratio_decimal_test"] = df["ratio"].apply(lambda x: len(x.split(".")[1]) > 3 if len(x.split(".")) > 1 else False)
                df["ratio_ends_with_zero"] = df["ratio"].apply(lambda x: int(x.split(".")[1]) == 0 if len(x.split(".")) > 1 else False)
                sum_violating_1 = sum(df['ratio_decimal_test'])
                sum_violating_2 = sum(df['ratio_ends_with_zero'])
                if sum_violating_1 > 0:
                    stream_write(f"ğŸ”” extend_stats -> ratio: {sum_violating_1} åˆ—è¶…é 3 ä½å°æ•¸" )
                if sum_violating_2 > 0:
                    stream_write(f"ğŸ”” extend_stats -> ratio: {sum_violating_2} åˆ—å°æ•¸ä»¥ 0 çµå°¾" )

            # * Check avg_price
            if "avg_price" in df.columns:
                df["avg_price"] = df["avg_price"].astype(str)
                df["avg_price_decimal_test"] = df["avg_price"].apply(lambda x: len(x.split(".")[1]) > 3 if len(x.split(".")) > 1 else False)
                df["avg_price_ends_with_zero"] = df["avg_price"].apply(lambda x: int(x.split(".")[1]) == 0 if len(x.split(".")) > 1 else False)
                sum_violating_1 = sum(df['avg_price_decimal_test'])
                sum_violating_2 = sum(df['avg_price_ends_with_zero'])
                if sum_violating_1 > 0:
                    stream_write(f"ğŸ”” extend_stats -> avg_price: {sum_violating_1} åˆ—è¶…é 3 ä½å°æ•¸" )
                if sum_violating_2 > 0:
                    stream_write(f"ğŸ”” extend_stats -> avg_price: {sum_violating_2} åˆ—å°æ•¸ä»¥ 0 çµå°¾" )

            del df
            stream_write("âœ… æª¢æŸ¥å®Œæˆ")
        else:
            stream_write("âœ… æ²’æœ‰ extend_stats æ¬„ä½")

    # ==========================================================================================================================
    # * * * ä»¥ä¸‹ç‚ºå„è¡¨çš„è³‡æ–™é©—è­‰å‡½æ•¸ã€‚æœƒç”¨åˆ°ä¸Šé¢çš„è¼”åŠ©å‡½æ•¸ * * * 
    # ==========================================================================================================================

    def check_products(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "products")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "products")

        # é‡è¤‡å€¼æª¢æ¸¬
        dup_ids = self.duplicates_analysis(data, "products")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        incorrect_classified_ids = self.classification_check(data)

        return dup_ids
        

    def check_products_extend(self, data):


        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "products_extend")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "products_extend")

        # é‡è¤‡å€¼æª¢æ¸¬
        dup_ids = self.duplicates_analysis(data, "products_extend")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data)

        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "products_extend")

        return dup_ids

    def check_chart_brands(self, data):
        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brands")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brands")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brands")
        
    def check_chart_brand(self, data):
        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brand")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brand")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brand")

    def check_chart_brands_extend_cross(self, data):
        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brands_extend_cross")
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brands_extend_cross")
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")
        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brands_extend_cross")
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brands_extend_cross")
        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brands_extend")
        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)
        self.verify_decimal(data)

    def check_chart_brands_extend_image(self, data):
        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brands_extend_image")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brands_extend_image")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.chart_brand_extend_image_details["incorrect_classified_ids"] = self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brands_extend_image")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brands_extend_image")
        
        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)
        
    def check_chart_brand_extend_image(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brand_extend_image")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brand_extend_image")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.chart_brand_extend_image_details["incorrect_classified_ids"] = self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brand_extend_image")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brand_extend_image")

        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)

    def check_chart_brands_comment_counts(self, data):
        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brands_comment_counts")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brands_comment_counts")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brands_comment_counts")
        
    def check_chart_brand_comment_counts(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brand_comment_counts")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brand_comment_counts")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brand_comment_counts")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_brand_comment_counts")

        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)

    def check_chart_brands_comment_score(self, data):
        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brands_comment_score")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brands_comment_score")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")
        
        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_brands_comment_score")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        stream_write("\nğŸ”† æª¢æŸ¥æ˜¯å¦ç¼ºå°‘æ“´å……å±¬æ€§...")
        
    def check_chart_brand_comment_score(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_brand_comment_score")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_brand_comment_score")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        stream_write("\nğŸ”† æª¢æŸ¥æ˜¯å¦ç¼ºå°‘æ“´å……å±¬æ€§...")
        extend_classes_status = pd.DataFrame(columns = Extend_class_schema["chart_brand_comment_score"])
        for col in extend_classes_status.columns:
            if col not in data['extend_class'].unique():
                extend_classes_status.loc["æ˜¯å¦å‡ºç¾åœ¨è³‡æ–™è¡¨ä¸­", col] = "âŒ"
            else:
                extend_classes_status.loc["æ˜¯å¦å‡ºç¾åœ¨è³‡æ–™è¡¨ä¸­", col] = "âœ…"
        st.dataframe(extend_classes_status)
    
    def check_chart_others(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_others")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_others")
    
        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_others")
        
        # æª¢æŸ¥æ“´å……å±¬æ€§
        self.check_extend_class(data, "chart_others")

        # æª¢æŸ¥å°æ•¸é»
        self.verify_decimal(data)

    def check_chart_trends(self, data):

        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "chart_trends")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "chart_trends")


        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "mixed")

        # é©—è­‰æ’å
        self.rank_verifier(data, "chart_trends")

    def check_reference(self, data):
        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "reference")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "reference")

        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        self.classification_check(data, "further_subcategory")

    def check_keyword(self, data):
        # æª¢æŸ¥é‡è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        self.column_assertion(data, "keyword")
        
        # é‡è¦æ¬„ä½ç©ºå€¼åˆ†æ
        self.null_analysis(data, "keyword")

        for col in ["domain", "subcategory", "further_subcategory", "category"]:
            data[col] = data[col].astype(str)

        is_brand_t = data[data['is_brand'] == True]
        is_brand_f = data[data['is_brand'] == False]
        
        # æª¢æŸ¥æ˜¯å¦æœ‰åˆ—çš„ search_volume ç‚º 0
        stream_write("\nğŸ”† æª¢æŸ¥ keyword è¡¨ä¸­çš„ search_volume æ¬„ä½...")
        try:
            data["search_volume_zero"] = data['search_volume'].apply(
                lambda x: pd.isna(x) or str(x).strip() in ['0', '0.0', ''] or (
                    isinstance(x, (int, float)) and x == 0
                )
            )
            zero_count = int(data['search_volume_zero'].sum())
            if zero_count == 0:
                stream_write(f"âœ… æ²’æœ‰ search_volume ç‚º 0 æˆ–ç©ºå€¼çš„è³‡æ–™")
            else:
                stream_write(f"ğŸ”” å…±æœ‰ {zero_count} åˆ—ä¹‹ search_volume ç‚º 0 æˆ–ç©ºå€¼ï¼")
        except Exception as e:
            stream_write(f"âš ï¸ æª¢æŸ¥ search_volume æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

        # æª¢æŸ¥ç”¢å“åˆ†é¡çµ„åˆ
        # stream_write("\nğŸ”† æª¢æŸ¥ is_brand = True çš„è³‡æ–™åˆ†é¡...")
        self.classification_check(is_brand_t, "further_subcategory")
        safe_st_call(st.caption, "é‡å° is_brand = 1 ä¹‹ keyword è³‡æ–™")

        # stream_write("\nğŸ”† æª¢æŸ¥ is_brand = False çš„è³‡æ–™åˆ†é¡...")
        self.classification_check(is_brand_f, "further_subcategory")
        safe_st_call(st.caption, "é‡å° is_brand = 0 ä¹‹ keyword è³‡æ–™")
        
    def check_category_coverage(self, data, level="further_subcategory"):
        """
        æª¢æŸ¥ä¸Šå‚³çš„è¡¨æ ¼æ˜¯å¦åŒ…å«æ‰€æœ‰åˆ†é¡
        
        Parameters:
        -----------
        data : pandas DataFrame
            è¦æª¢æŸ¥çš„è³‡æ–™
        level : str
            æª¢æŸ¥çš„åˆ†é¡å±¤ç´šï¼Œå¯ä»¥æ˜¯ "subcategory" æˆ– "further_subcategory"
            
        Returns:
        --------
        list
            ç¼ºå¤±çš„åˆ†é¡åˆ—è¡¨
        """
        safe_st_call(st.divider)
        stream_write("\nğŸ”† æª¢æŸ¥åˆ†é¡è¦†è“‹ç‡...")
        
        # ç¢ºå®šæª¢æŸ¥çš„åˆ†é¡å±¤ç´š
        if level == "further_subcategory":
            categories = self.classification['classification_further_subcategory'].tolist()
            class_cols = classification_columns
        else:
            categories = self.classification['classification_subcategory'].tolist()
            class_cols = ["category", "subcategory"]
        
        # æª¢æŸ¥å¿…è¦çš„æ¬„ä½æ˜¯å¦å­˜åœ¨
        missing_cols = [col for col in class_cols if col not in data.columns]
        if missing_cols:
            stream_write(f"âš ï¸ è³‡æ–™ç¼ºå°‘å¿…è¦çš„åˆ†é¡æ¬„ä½: {missing_cols}")
            stream_write("ç„¡æ³•é€²è¡Œåˆ†é¡è¦†è“‹ç‡æª¢æŸ¥")
            return []
        
        # è¨ˆç®—æ¯å€‹åˆ†é¡çš„æ•¸é‡
        result = []
        for category in categories:
            if level == "further_subcategory":
                # æ‹†åˆ†åˆ†é¡å­—ä¸²ä»¥ä¾¿æ¯”å°
                cat_parts = category.split('_')
                if len(cat_parts) != 3:
                    continue
                    
                # ç¯©é¸å‡ºç¬¦åˆè©²åˆ†é¡çš„è³‡æ–™
                mask = ((data['category'] == cat_parts[0]) & 
                       (data['subcategory'] == cat_parts[1]) & 
                       (data['further_subcategory'] == cat_parts[2]))
            else:
                cat_parts = category.split('_')
                if len(cat_parts) != 2:
                    continue
                    
                mask = ((data['category'] == cat_parts[0]) & 
                       (data['subcategory'] == cat_parts[1]))
            
            count = mask.sum()
            result.append({
                'category': category,
                'count': count
            })
        
        # è½‰æ›ç‚º DataFrame
        df_result = pd.DataFrame(result)
        
        # æ‰¾å‡ºç¼ºå¤±çš„åˆ†é¡ (count == 0)
        missing_categories = df_result[df_result['count'] == 0]['category'].tolist()
        
        # å„²å­˜çµæœ
        self.category_coverage_details['result'] = df_result
        self.category_coverage_details['missing'] = missing_categories
        
        # é¡¯ç¤ºçµæœ
        styled_df = self._style_category_coverage(df_result)
        stream_write(f"ğŸ”” åˆ†é¡è¦†è“‹ç‡æª¢æŸ¥çµæœï¼ˆå…± {len(categories)} å€‹åˆ†é¡ï¼Œç¼ºå¤± {len(missing_categories)} å€‹ï¼‰ï¼š")
        st.dataframe(styled_df)
        
        # å¦‚æœæœ‰ç¼ºå¤±çš„åˆ†é¡ï¼Œæä¾›ä¸‹è¼‰æŒ‰éˆ•
        if missing_categories:
            st.download_button(
                label = "ä¸‹è¼‰ç¼ºå¤±åˆ†é¡æ¸…å–®",
                data = "\n".join(missing_categories),
                file_name = "missing_categories.txt",
                mime = "text/plain"
            )
            
        return missing_categories
        
    def _style_category_coverage(self, df):
        """
        ç‚ºåˆ†é¡è¦†è“‹ç‡çµæœæ·»åŠ æ¨£å¼
        
        Parameters:
        -----------
        df : pandas DataFrame
            è¦æ·»åŠ æ¨£å¼çš„è³‡æ–™
            
        Returns:
        --------
        pandas DataFrame
            å¸¶æœ‰æ¨£å¼çš„è³‡æ–™
        """
        # ä½¿ç”¨ pandas styler API ä¾†è¨­ç½®æ¨£å¼
        def highlight_zero(val):
            return 'background-color: #FFCCCC' if val == 0 else ''
        
        # å°‡æ¨£å¼æ‡‰ç”¨åˆ° 'count' åˆ—
        styled_df = df.style.map(highlight_zero, subset=['count'])
        
        return styled_df
    
    def check_category_coverage_stats(self):
        """
        æª¢æŸ¥é¡åˆ¥è¦†è“‹ç‡çµ±è¨ˆ
        
        Returns:
        --------
        dict
            åŒ…å«å„åˆ†é¡å±¤ç´šè¦†è“‹ç‡å’Œæ˜¯å¦é€šéé–¾å€¼æª¢æŸ¥çš„çµæœ
        """
        # ç²å–ç•¶å‰è³‡æ–™çš„å”¯ä¸€åˆ†é¡å€¼
        current_counts = {
            'å¤§åˆ†é¡': len(self.classification['category'].unique()) if 'category' in self.classification.columns else 0,
            'ä¸­åˆ†é¡': len(self.classification['subcategory'].unique()) if 'subcategory' in self.classification.columns else 0,
            'å°åˆ†é¡': len(self.classification['further_subcategory'].unique()) if 'further_subcategory' in self.classification.columns else 0
        }
        
        # ç²å–ç¸½é¡åˆ¥æ•¸é‡
        total_counts = self.get_total_category_counts()
        
        # è¨ˆç®—è¦†è“‹ç‡
        coverage = {
            'å¤§åˆ†é¡è¦†è“‹ç‡': current_counts['å¤§åˆ†é¡'] / total_counts['å¤§åˆ†é¡'] if total_counts['å¤§åˆ†é¡'] > 0 else 0,
            'ä¸­åˆ†é¡è¦†è“‹ç‡': current_counts['ä¸­åˆ†é¡'] / total_counts['ä¸­åˆ†é¡'] if total_counts['ä¸­åˆ†é¡'] > 0 else 0,
            'å°åˆ†é¡è¦†è“‹ç‡': current_counts['å°åˆ†é¡'] / total_counts['å°åˆ†é¡'] if total_counts['å°åˆ†é¡'] > 0 else 0
        }
        
        # åˆ¤æ–·æ˜¯å¦é€šé
        passed = all(rate >= CATEGORY_COVERAGE_THRESHOLD for rate in coverage.values())
        
        # è¿”å›çµæœ
        return {
            **coverage,
            'é–¾å€¼': CATEGORY_COVERAGE_THRESHOLD,
            'é€šé': passed
        }
    
    def get_total_category_counts(self):
        """
        ç²å–æ¨™æº–åˆ†é¡è¡¨ä¸­å„å±¤ç´šçš„ç¸½é¡åˆ¥æ•¸é‡
        
        Returns:
        --------
        dict
            å„åˆ†é¡å±¤ç´šçš„ç¸½æ•¸é‡
        """
        if hasattr(self, 'classification') and isinstance(self.classification, pd.DataFrame):
            # ä½¿ç”¨ç›¸åŒçš„æ¬„ä½åç¨±ä¾†ç²å–è¨ˆæ•¸
            return {
                'å¤§åˆ†é¡': len(self.classification['category'].unique()) if 'category' in self.classification.columns else 0,
                'ä¸­åˆ†é¡': len(self.classification['subcategory'].unique()) if 'subcategory' in self.classification.columns else 0,
                'å°åˆ†é¡': len(self.classification['further_subcategory'].unique()) if 'further_subcategory' in self.classification.columns else 0
            }
        else:
            # å¦‚æœæ²’æœ‰æ¨™æº–åˆ†é¡è¡¨ï¼Œè¿”å›é è¨­å€¼
            return {'å¤§åˆ†é¡': 1, 'ä¸­åˆ†é¡': 1, 'å°åˆ†é¡': 1}

    def check_empty_cells(self):
        """
        æª¢æŸ¥è³‡æ–™ä¸­çš„ç©ºå€¼å„²å­˜æ ¼
        
        Returns:
        --------
        dict
            åŒ…å«å„æ¬„ä½ç©ºå€¼æ•¸é‡çš„å­—å…¸
        """
        empty_cells = {}
        
        if hasattr(self, 'classification') and isinstance(self.classification, pd.DataFrame):
            # è¨ˆç®—æ¯å€‹æ¬„ä½çš„ç©ºå€¼æ•¸é‡
            for col in self.classification.columns:
                null_count = self.classification[col].isna().sum()
                if null_count > 0:
                    empty_cells[col] = null_count
                    
            # ä¿å­˜è©³ç´°è³‡è¨Š
            self.empty_cells_details = empty_cells
            
            # åœ¨ streamlit ç’°å¢ƒä¸­é¡¯ç¤ºçµæœï¼ˆå¦‚æœæ˜¯åœ¨æ‡‰ç”¨ä¸­é‹è¡Œï¼‰
            try:
                if empty_cells:
                    st.write("ğŸ”† è³‡æ–™ä¸­å­˜åœ¨ç©ºå€¼å„²å­˜æ ¼ï¼š")
                    st.dataframe(pd.DataFrame(list(empty_cells.items()), columns=['æ¬„ä½', 'ç©ºå€¼æ•¸é‡']))
                else:
                    st.write("âœ… è³‡æ–™ä¸­æ²’æœ‰ç©ºå€¼å„²å­˜æ ¼")
            except (AttributeError, NameError):
                # å¦‚æœåœ¨æ¸¬è©¦ç’°å¢ƒï¼Œå¿½ç•¥ streamlit é¡¯ç¤º
                pass
                
        return empty_cells
    
    def check_duplicated_products(self):
        """
        æª¢æŸ¥é‡è¤‡çš„ç”¢å“è³‡æ–™
        
        Returns:
        --------
        list
            é‡è¤‡ç”¢å“çš„ç´¢å¼•åˆ—è¡¨
        """
        duplicates = []
        
        if hasattr(self, 'classification') and isinstance(self.classification, pd.DataFrame):
            # æ ¹æ“šç”¢å“åç¨±æª¢æŸ¥é‡è¤‡
            if 'ç”¢å“åç¨±' in self.classification.columns:
                dup_mask = self.classification.duplicated(subset=['ç”¢å“åç¨±'], keep=False)
                duplicates = self.classification[dup_mask].index.tolist()
                
                # ä¿å­˜è©³ç´°è³‡è¨Š
                self.duplicated_products_details = {
                    'count': len(duplicates),
                    'indices': duplicates
                }
                
                # åœ¨ streamlit ç’°å¢ƒä¸­é¡¯ç¤ºçµæœï¼ˆå¦‚æœæ˜¯åœ¨æ‡‰ç”¨ä¸­é‹è¡Œï¼‰
                try:
                    if duplicates:
                        st.write(f"ğŸ”” ç™¼ç¾ {len(duplicates)} ç­†é‡è¤‡çš„ç”¢å“è³‡æ–™")
                        st.dataframe(self.classification[dup_mask])
                    else:
                        st.write("âœ… æ²’æœ‰é‡è¤‡çš„ç”¢å“è³‡æ–™")
                except (AttributeError, NameError):
                    # å¦‚æœåœ¨æ¸¬è©¦ç’°å¢ƒï¼Œå¿½ç•¥ streamlit é¡¯ç¤º
                    pass
                    
        return duplicates
    
    def check_brands(self):
        """
        æª¢æŸ¥å“ç‰Œè³‡æ–™
        
        Returns:
        --------
        dict
            å“ç‰Œçµ±è¨ˆè³‡è¨Š
        """
        brand_stats = {}
        
        if hasattr(self, 'classification') and isinstance(self.classification, pd.DataFrame):
            # æª¢æŸ¥å“ç‰Œæ¬„ä½æ˜¯å¦å­˜åœ¨
            if 'å“ç‰Œ' in self.classification.columns:
                # çµ±è¨ˆæ¯å€‹å“ç‰Œçš„æ•¸é‡
                brand_counts = self.classification['å“ç‰Œ'].value_counts()
                
                # è½‰æ›ç‚ºå­—å…¸
                brand_stats = brand_counts.to_dict()
                
                # åœ¨ streamlit ç’°å¢ƒä¸­é¡¯ç¤ºçµæœï¼ˆå¦‚æœæ˜¯åœ¨æ‡‰ç”¨ä¸­é‹è¡Œï¼‰
                try:
                    st.write("ğŸ”† å“ç‰Œçµ±è¨ˆè³‡è¨Šï¼š")
                    st.dataframe(pd.DataFrame(list(brand_stats.items()), columns=['å“ç‰Œ', 'æ•¸é‡']))
                except (AttributeError, NameError):
                    # å¦‚æœåœ¨æ¸¬è©¦ç’°å¢ƒï¼Œå¿½ç•¥ streamlit é¡¯ç¤º
                    pass
                
        return brand_stats
    
    def chart_brands_category(self):
        """
        ç”Ÿæˆå“ç‰Œèˆ‡å¤§åˆ†é¡çš„äº¤å‰çµ±è¨ˆåœ–è¡¨
        """
        if hasattr(self, 'classification') and isinstance(self.classification, pd.DataFrame):
            # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
            if 'å“ç‰Œ' in self.classification.columns and 'category' in self.classification.columns:
                # ç”Ÿæˆäº¤å‰è¡¨
                cross_tab = pd.crosstab(
                    self.classification['å“ç‰Œ'], 
                    self.classification['category']
                )
                
                # åœ¨ streamlit ç’°å¢ƒä¸­é¡¯ç¤ºçµæœï¼ˆå¦‚æœæ˜¯åœ¨æ‡‰ç”¨ä¸­é‹è¡Œï¼‰
                try:
                    st.write("ğŸ”† å“ç‰Œèˆ‡å¤§åˆ†é¡äº¤å‰çµ±è¨ˆï¼š")
                    st.dataframe(cross_tab)
                except (AttributeError, NameError):
                    # å¦‚æœåœ¨æ¸¬è©¦ç’°å¢ƒï¼Œå¿½ç•¥ streamlit é¡¯ç¤º
                    pass
                
                # ä¿å­˜è©³ç´°è³‡è¨Š
                self.chart_brand_details["category"] = cross_tab.to_dict()
                
    def chart_brands_subcategory(self):
        """
        ç”Ÿæˆå“ç‰Œèˆ‡ä¸­åˆ†é¡çš„äº¤å‰çµ±è¨ˆåœ–è¡¨
        """
        if hasattr(self, 'classification') and isinstance(self.classification, pd.DataFrame):
            # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
            if 'å“ç‰Œ' in self.classification.columns and 'subcategory' in self.classification.columns:
                # ç”Ÿæˆäº¤å‰è¡¨
                cross_tab = pd.crosstab(
                    self.classification['å“ç‰Œ'], 
                    self.classification['subcategory']
                )
                
                # åœ¨ streamlit ç’°å¢ƒä¸­é¡¯ç¤ºçµæœï¼ˆå¦‚æœæ˜¯åœ¨æ‡‰ç”¨ä¸­é‹è¡Œï¼‰
                try:
                    st.write("ğŸ”† å“ç‰Œèˆ‡ä¸­åˆ†é¡äº¤å‰çµ±è¨ˆï¼š")
                    st.dataframe(cross_tab)
                except (AttributeError, NameError):
                    # å¦‚æœåœ¨æ¸¬è©¦ç’°å¢ƒï¼Œå¿½ç•¥ streamlit é¡¯ç¤º
                    pass
                
                # ä¿å­˜è©³ç´°è³‡è¨Š
                self.chart_brand_details["subcategory"] = cross_tab.to_dict()
    
    def generate_verification_report(self):
        """
        ç”Ÿæˆé©—è­‰å ±å‘Š
        
        Returns:
        --------
        dict
            åŒ…å«æ‰€æœ‰é©—è­‰çµæœçš„å ±å‘Š
        """
        # è™•ç† numpy é¡å‹çš„å•é¡Œï¼Œè½‰ç‚º Python åŸç”Ÿé¡å‹
        def convert_numpy_to_native(obj):
            if hasattr(obj, 'items'):
                return {k: convert_numpy_to_native(v) for k, v in obj.items()}
            elif hasattr(obj, '__iter__') and not isinstance(obj, str):
                return [convert_numpy_to_native(v) for v in obj]
            elif hasattr(obj, 'item'):
                return obj.item()  # å°‡ numpy é¡å‹è½‰ç‚º Python åŸç”Ÿé¡å‹
            else:
                return obj
            
        # è½‰æ› empty_cells_details
        if self.empty_cells_details:
            self.empty_cells_details = convert_numpy_to_native(self.empty_cells_details)
            
        report = {
            'empty_cells': self.empty_cells_details,
            'duplicate_products': self.duplicated_products_details,
            'category_coverage': self.category_coverage_details,
            'brands': self.chart_brand_details
        }
        
        # æ·»åŠ æª”æ¡ˆåç¨±ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.file_name:
            report['file_name'] = self.file_name
        
        # è¨ˆç®—å•é¡Œç¸½æ•¸
        empty_cell_count = sum(self.empty_cells_details.values()) if self.empty_cells_details else 0
        duplicate_count = self.duplicated_products_details.get('count', 0) if self.duplicated_products_details else 0
        
        summary = pd.DataFrame({
            'é …ç›®': ['ç©ºå€¼å„²å­˜æ ¼æ•¸é‡', 'é‡è¤‡ç”¢å“æ•¸é‡'],
            'æ•¸é‡': [empty_cell_count, duplicate_count]
        })
        
        # åœ¨ streamlit ç’°å¢ƒä¸­é¡¯ç¤ºå ±å‘Šæ‘˜è¦ï¼ˆå¦‚æœæ˜¯åœ¨æ‡‰ç”¨ä¸­é‹è¡Œï¼‰
        try:
            st.write("ğŸ“‹ é©—è­‰å ±å‘Šæ‘˜è¦ï¼š")
            st.dataframe(summary)
            
            # æä¾›ä¸‹è¼‰å ±å‘Šçš„æŒ‰éˆ•
            if self.file_name:
                # è½‰æ›å ±å‘Šä¸­çš„æ‰€æœ‰ numpy é¡å‹ç‚º Python åŸç”Ÿé¡å‹
                json_safe_report = convert_numpy_to_native(report)
                
                st.download_button(
                    label="ä¸‹è¼‰é©—è­‰å ±å‘Š",
                    data=json.dumps(json_safe_report, ensure_ascii=False, indent=2),
                    file_name=f"{self.file_name.split('.')[0]}_verification_report.json",
                    mime="application/json"
                )
        except (AttributeError, NameError):
            # å¦‚æœåœ¨æ¸¬è©¦ç’°å¢ƒï¼Œå¿½ç•¥ streamlit é¡¯ç¤º
            pass
            
        return report


